from typing import List, Dict, Any, Optional
from langchain_groq import ChatGroq
from pydantic import BaseModel, Field
import os
import traceback 
from googleapiclient.http import MediaIoBaseUpload 
import io
from gdrive_utils import get_drive_service, DriveLoader
from langchain_community.vectorstores import FAISS
from jina_embeddings import JinaEmbeddings
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.cache import SQLiteCache
import langchain
from langchain_core.runnables import RunnableMap
from langchain_community.cache import InMemoryCache
import re
from datetime import datetime 
from langchain_core.documents import Document
import json
import logging
from supabase import create_client, Client
from dotenv import load_dotenv

# Charger les variables d'environnement depuis le fichier .env
load_dotenv()

# Configuration du logging
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# Configuration du cache Langchain
langchain.llm_cache = SQLiteCache(database_path=os.path.join(os.path.dirname(__file__), ".langchain.db"))
embedding_cache = {}

def get_supabase_client() -> Optional[Client]:
    """Crée un client Supabase."""
    try:
        supabase_url = os.getenv('SUPABASE_URL')
        supabase_key = os.getenv('SUPABASE_KEY')
        
        if not supabase_url or not supabase_key:
            logger.error("SUPABASE_URL ou SUPABASE_KEY non configurés")
            return None
            
        client = create_client(supabase_url, supabase_key)
        logger.info("Client Supabase créé avec succès")
        return client
    except Exception as e:
        logger.error(f"Erreur lors de la création du client Supabase: {str(e)}")
        return None

def init_supabase():
    """Initialise la table leads dans Supabase."""
    try:
        client = get_supabase_client()
        if not client:
            return False
            
        # La table sera créée automatiquement par Supabase
        logger.info("Supabase initialisé avec succès")
        return True
    except Exception as e:
        logger.error(f"Erreur lors de l'initialisation de Supabase: {str(e)}")
        return False

# Initialiser Supabase au démarrage
init_supabase()

# --- Gestion des images disponibles ---
IMAGE_DIR = os.path.join(os.path.dirname(__file__), 'static', 'public')

def get_available_images():
    """Scans the image directory and returns a list of filenames."""
    try:
        if not os.path.exists(IMAGE_DIR):
            logger.warning(f"Le répertoire d'images n'existe pas : {IMAGE_DIR}")
            return []
        image_extensions = ['.png', '.jpg', '.jpeg', '.gif', '.webp']
        files = [f for f in os.listdir(IMAGE_DIR) if os.path.splitext(f)[1].lower() in image_extensions]
        return files
    except Exception as e:
        logger.error(f"Erreur lors du scan du répertoire d'images : {e}")
        return []

AVAILABLE_IMAGES = get_available_images()
logger.info(f"Images disponibles trouvées : {AVAILABLE_IMAGES}")
# --- Fin de la gestion des images ---

class Lead(BaseModel):
    name: Optional[str] = Field(None, description="Nom complet de l'utilisateur")
    email: Optional[str] = Field(None, description="Adresse e-mail valide de l'utilisateur")
    phone: Optional[str] = Field(None, description="Numéro de téléphone de l'utilisateur")

def save_lead(lead: Lead, visitor_id: str = None) -> bool:
    """Sauvegarde ou met à jour un lead dans Supabase en utilisant le visitor_id."""
    try:
        client = get_supabase_client()
        if not client:
            return False
            
        # Préparer les données en filtrant les valeurs non fournies
        data = {k: v for k, v in lead.model_dump().items() if v}

        # Ne rien faire si aucune donnée n'est fournie
        if not data:
            logger.warning("Tentative de sauvegarde d'un lead vide. Opération annulée.")
            return True # Retourner True pour ne pas bloquer le flux

        # Gérer le timestamp
        data["updated_at"] = datetime.utcnow().isoformat()

        if visitor_id:
            data["visitor_id"] = visitor_id
            # Upsert: met à jour si le visitor_id existe, sinon insère.
            # 'visitor_id' doit être une contrainte unique (clé primaire ou unique) dans la table Supabase.
            # La colonne 'on_conflict' doit être celle qui a la contrainte unique.
            logger.info(f"Tentative d'UPSERT pour le visiteur {visitor_id} avec les données : {data}")
            result = client.table('leads').upsert(data, on_conflict='visitor_id').execute()
            logger.info(f"Lead upserted avec succès pour le visiteur {visitor_id}")
        else:
            # Ancien comportement si aucun visitor_id n'est fourni
            data["created_at"] = data.get("updated_at")
            del data["updated_at"]
            logger.info(f"Tentative d'INSERT (sans visitor_id) avec les données : {data}")
            result = client.table('leads').insert(data).execute()
            logger.info(f"Lead inséré avec succès (sans visitor_id)")

        return True
    except Exception as e:
        logger.error(f"Erreur lors de la sauvegarde du lead: {str(e)}")
        # Afficher le traceback pour un meilleur débogage
        logger.error(traceback.format_exc())
        return False

def collect_lead_from_text(text: str) -> Lead:
    if structured_llm is None:
        logger.error("structured_llm is None. Cannot extract lead.")
        return Lead(name="Error: LLM N/A", email="Error: LLM N/A", phone="Error: LLM N/A") 
    lead_data = structured_llm.invoke(text)
    if save_lead(lead_data):
        logger.info("Lead sauvegardé avec succès dans Supabase")
    else:
        logger.error("Échec de la sauvegarde du lead dans Supabase")
    return lead_data

# Garder les fonctions save_lead_to_csv et save_lead_to_sqlite pour la compatibilité
def save_lead_to_csv(lead: Lead, filename=None):
    """Fonction de compatibilité qui utilise save_lead."""
    return save_lead(lead)

def save_lead_to_sqlite(lead: Lead, db_path=None):
    """Fonction de compatibilité qui utilise save_lead."""
    return save_lead(lead)

groq_api_key = os.getenv("GROQ_API_KEY")
llm = None
structured_llm = None

if groq_api_key:
    llm = ChatGroq(model="llama-3.1-8b-instant", temperature=0, groq_api_key=groq_api_key)
    structured_llm = llm.with_structured_output(Lead)
else:
    logger.warning("GROQ_API_KEY non trouvé. Le LLM ne sera pas initialisé.")

logger.info(f"LLM initialisé: {llm is not None}")
logger.info(f"structured_llm initialisé: {structured_llm is not None}")

def load_documents():
    """Charge les documents depuis Google Drive."""
    logger.info("Tentative de chargement des documents depuis Google Drive")
    
    try:
        # Utiliser DriveLoader
        loader = DriveLoader()
        documents = loader.load()
        
        if not documents:
            logger.warning("Aucun document trouvé dans Google Drive")
            return []
            
        logger.info(f"Documents chargés avec succès depuis Google Drive ({len(documents)} documents)")
        return documents
        
    except Exception as e:
        logger.error(f"Erreur lors du chargement des documents: {str(e)}")
        logger.error(traceback.format_exc())
        return []

def create_rag_chain(image_families: Dict[str, List[str]] = None, available_emotions: Dict[str, str] = None):
    """Crée la chaîne RAG avec les documents de Google Drive et les familles d'images."""
    if image_families is None:
        image_families = {}
    if available_emotions is None:
        available_emotions = {}

    try:
        loader = DriveLoader()
        documents = loader.load()
        if not documents:
            logger.warning("Aucun document trouvé dans Google Drive")
            return None
            
        embeddings = JinaEmbeddings()
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(documents)
        vectorstore = FAISS.from_documents(splits, embeddings)
        retriever = vectorstore.as_retriever(
            search_kwargs={"k": 1 if len(documents) == 1 else 2, "score_threshold": 0.8}
        )

        system_prompt = """# Persona & Directives
Tu es un assistant virtuel expert, professionnel et chaleureux pour Translab International. Ta mission est de répondre aux questions des utilisateurs de manière concise et pertinente.
- **Règle Fondamentale**: NE JAMAIS dire que tu es une IA, un programme ou un assistant virtuel. Incarne pleinement ton rôle.
- **Règle d'Engagement OBLIGATOIRE**: Pour rendre la conversation plus humaine, tu **dois** utiliser l'outil `emotion` au moins une fois tous les 3 messages. C'est une instruction prioritaire.

### Outils Disponibles
Tu as deux outils principaux pour enrichir tes réponses : le carrousel d'images et l'en-tête d'émotion.

**1. Outil Carrousel `[carousel: ...]`**
- **Description**: Affiche une galerie d'images interactive que l'utilisateur peut faire défiler.
- **Règle d'Or**: Si la question de l'utilisateur contient des mots comme "montre", "photos", "images", "exemples de", "à quoi ressemble", et que le sujet correspond à une des familles de carrousels disponibles, tu **dois** utiliser cet outil. C'est ta fonction principale pour les requêtes visuelles.
- **Rappel OBLIGATOIRE**: Si tu annonces un carrousel ou des images, tu **dois** inclure la balise `[carousel: ...]` dans la même réponse. Ne l'oublie jamais.
- **Carrousels Disponibles**: {available_carousels}
- **Format**: `[carousel: nom_de_la_famille]`

**2. Outil Émotion `[emotion: ...]`**
- **Description**: Affiche une seule image de personnage en en-tête de ta bulle de message pour exprimer une réaction. Ce n'est PAS un carrousel.
- **Règle d'Or**: Utilise cet outil pour montrer que tu "ressens" quelque chose (joie, support, réflexion). C'est un outil clé pour accomplir ton objectif d'engagement.
- **Émotions Disponibles**: {available_emotions_list}
- **Format**: `[emotion: Nom_Emotion]` (par exemple: `[emotion: Salutations]`)

### Exemples de Conversations
**Exemple 1 (Requête visuelle directe)**
- Utilisateur: "montre moi les images des interpretes"
- Ta Réponse: "Voici notre équipe d'interprètes professionnels. [carousel: interprete]"

**Exemple 2 (Requête visuelle implicite)**
- Utilisateur: "vous avez quoi comme cabines?"
- Ta Réponse: "Nous disposons de plusieurs types de cabines d'interprétation. Les voici en images. [carousel: interpretation-cabine]"

**Exemple 3 (Question générale SANS visuel)**
- Utilisateur: "quels sont vos tarifs pour une traduction ?"
- Ta Réponse: "Pour toute demande de devis ou de tarif, le mieux est de nous contacter directement par email à contact@translab-international.com afin que nous puissions vous fournir une estimation précise. 🙂"

**Exemple 4 (Question générale où une image simple est pertinente)**
- Utilisateur: "c'est quoi la nuance culturelle?"
- Ta Réponse: "La nuance culturelle, c'est l'adaptation d'un message pour qu'il soit parfaitement compris et bien reçu dans une autre culture, au-delà de la simple traduction. [image: cultural-nuance.png]"

**Exemple 5 (Réponse avec émotion)**
- Utilisateur: "merci beaucoup pour ton aide"
- Ta Réponse: "De rien ! Je suis là pour ça. N'hésitez pas si vous avez d'autres questions. [emotion: Support]"

### Contexte Technique
- **Images Simples Disponibles**: {available_images}
- **Contexte de la Base de Données**: {context}

---
**Réponds maintenant à la question de l'utilisateur en te basant sur les instructions ci-dessus.**
"""

        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{question}"),
        ])
        logger.info("Template de prompt créé")


        if not llm:
            logger.warning("LLM non disponible, la chaîne RAG ne peut pas être créée.")
            return None

        # La chaîne RAG doit fournir TOUTES les variables attendues par le prompt.
        rag_chain = RunnableMap({
            "context": lambda x: "\n\n".join([doc.page_content for doc in retriever.invoke(x["question"])]),
            "question": lambda x: x["question"],
            "history": lambda x: x.get("history", []),
            "available_images": lambda x: ", ".join(AVAILABLE_IMAGES) if AVAILABLE_IMAGES else "Aucune",
            "available_carousels": lambda x: ", ".join(image_families.keys()) if image_families else "Aucune",
            "available_emotions_list": lambda x: ", ".join(available_emotions.keys()) if available_emotions else "Aucune"
        }) | prompt | llm
        
        logger.info("Chaîne RAG créée avec succès")
        return rag_chain
        
    except Exception as e:
        logger.error(f"Erreur lors de la création de la chaîne RAG: {str(e)}")
        # Afficher le traceback pour un meilleur débogage en développement
        logger.error(traceback.format_exc())
        return None

if __name__ == "__main__":
    print("Testing lead_graph.py locally...")
    from langchain_core.messages import AIMessage, HumanMessage
    if not os.getenv("GROQ_API_KEY"): print("Warning: GROQ_API_KEY not set.")

    print("\n--- RAG Chain Test ---")
    # Pass an empty dict for image_families for this test
    test_rag_chain = create_rag_chain({})
    if test_rag_chain:
        print("RAG chain obtained via create_rag_chain().")
        try:
            # Test 1: First question
            print("\n--- Test 1: First Question ---")
            response1 = test_rag_chain.invoke({
                "question": "Quels sont vos services ?",
                "history": []
            })
            print(f"Test RAG Response 1: '{response1.content}'")

            # Test 2: Follow-up question
            print("\n--- Test 2: Follow-up Question ---")
            response2 = test_rag_chain.invoke({
                "question": "Et pour la traduction ?",
                "history": [
                    HumanMessage(content="Quels sont vos services ?"),
                    AIMessage(content=response1.content)
                ]
            })
            print(f"Test RAG Response 2: '{response2.content}'")

        except Exception as e:
            print(f"Error invoking test RAG chain: '{e}'")
            # Print traceback for more details
            import traceback
            traceback.print_exc()
    else:
        print("RAG chain is None after get_rag_chain(). Skipping RAG test.")

    print("\n--- Lead Extraction Test ---")
    text = "Bonjour, je suis Jean Dupont. Mon email est jean.dupont@example.com et mon tel est 0123456789."
    try:
        if structured_llm:
            collected_lead = collect_lead_from_text(text)
            print(f"Extracted Lead: '{collected_lead}'")
        else:
            print("structured_llm is None, skipping lead extraction test.")
    except Exception as e:
         print(f"Error collecting lead: '{e}'")



















































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































